{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop 01 - TF Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT - The Frequency Fourier Transform\n",
    "Considering a time-domain ($t$) signal $g(t)$ that satisfies the Dirichlet's conditions:\n",
    "1. **Bounded**: $\\quad\\quad\\quad\\quad\\quad\\quad\\quad -\\infty<g(t)<\\infty$ and single-valued, $\\forall t \\in \\mathbb{R}$\n",
    "2. **Interval Divisable**: $\\quad\\quad\\quad\\quad g(t)$ is discontinued in a finite number of points\n",
    "3. **Absolutely Integrable**: $\\quad\\quad \\int_{-\\infty}^{\\infty} |g(t)| dt < \\infty $ \n",
    "\n",
    "The Fourier Transform $G(f)$ of the signal $g(t)$ is defined by:\n",
    "\n",
    "$\\quad \\quad G(f) = \\int_{-\\infty}^{\\infty} g(t) \\exp(-j2 \\pi ft) dt$,\n",
    "\n",
    "where $j=\\sqrt{-1}$, $f$ stands for frequency and $G(f) \\in \\mathbb{C}$.\n",
    "\n",
    "Conversely, a transformed signal can be recovered by:\n",
    "\n",
    "$\\quad \\quad g(t) = \\int_{-\\infty}^{\\infty} G(f) \\exp(+j2 \\pi ft) df$,\n",
    "\n",
    "which stands for the Inverse FFT (IFFT).\n",
    "\n",
    "**(Remember)** A complex number $z$ can be represented in many forms as:\n",
    "\n",
    "$z = x +jy = r e^{j \\varphi} = r (cos \\varphi + j sin \\varphi) $\n",
    "\n",
    "<img src=\"images/wikipedia_complex_numbers.svg.png\" alt=\"Complex Numbers\" width=150px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. Hands-On  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MODULES\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CONSTANTS\n",
    "SR = 16000\n",
    "FEMALE_AUDIOPATH = \"example_signals/librispeech_female84_i_am_going.wav\"\n",
    "MALE_AUDIOPATH = \"example_signals/librispeech_male251_i_am_going.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOL FUNCTIONS\n",
    "def read_wav(audio_path):\n",
    "    sr, audio = scipy.io.wavfile.read(audio_path)\n",
    "    return audio, sr\n",
    "\n",
    "def write_wav(audio_path, audio, sr):\n",
    "    #scipy.io.wavfile.write(audio_path, sr, audio)\n",
    "    sf.write(audio_path, 0.95*audio/np.max(audio), sr)\n",
    "    \n",
    "def display_audio(audio_path):\n",
    "    IPython.display.display(IPython.display.Audio(audio_path))\n",
    "\n",
    "def fft_transform(audio):\n",
    "    S = scipy.fft.fft(audio)\n",
    "    return S\n",
    "\n",
    "def ifft_transform(S):\n",
    "    audio = scipy.fft.ifft(S)\n",
    "    audio = np.real(audio) \n",
    "    return audio\n",
    "\n",
    "def line_plot_args(args, x_norm=1, subplot=True, x_range=None, labels=[\"X\",\"Y\"], legend=None):\n",
    "    plt.figure(figsize=(12,3))\n",
    "    n_figs = len(args)\n",
    "    \n",
    "    for idx, arg in enumerate(args):\n",
    "        xx = np.arange(len(arg)) / x_norm\n",
    "        \n",
    "        if x_range == None:\n",
    "            x_range = [0,len(arg)]\n",
    "\n",
    "        if subplot:\n",
    "            plt.subplot(1,n_figs,idx+1);\n",
    "        \n",
    "        plt.plot(xx[x_range[0]:x_range[1]], arg[x_range[0]:x_range[1]]) \n",
    "        plt.xlabel(labels[0]); plt.ylabel(labels[1]); plt.grid()\n",
    "    \n",
    "    if not subplot:\n",
    "        plt.legend(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ AUDIOS\n",
    "female_audio, sr = read_wav(FEMALE_AUDIOPATH)\n",
    "male_audio, sr = read_wav(MALE_AUDIOPATH)\n",
    "\n",
    "# PLOT AUDIOS\n",
    "line_plot_args([female_audio, male_audio], x_norm=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISTEN TO AUDIOS\n",
    "display_audio(FEMALE_AUDIOPATH)\n",
    "display_audio(MALE_AUDIOPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FFT\n",
    "S = fft_transform(female_audio)\n",
    "\n",
    "print(\"Shapes:\", female_audio.shape, S.shape,\"\\n\")\n",
    "\n",
    "print(\"S values:\")\n",
    "print(S[:5])\n",
    "print(S[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE IFFT\n",
    "ifft_female_audio = ifft_transform(S)\n",
    "print(ifft_female_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activity 01\n",
    "Considering the `male_audio` signal:\n",
    "- perform the FFT \n",
    "- reconstruct the signal with the IFFT and save it to `ifft_male_audio`\n",
    "- plot `male_audio` and `ifft_male_audio` signals superposed\n",
    "- quantify the absolute difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Module and Phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUXILIARY FUNCTIONS\n",
    "def fft_transform_abs_angle(audio):\n",
    "    S = fft_transform(audio)\n",
    "    return np.abs(S), np.angle(S)\n",
    "    #return np.abs(S), np.unwrap(np.angle(S))\n",
    "\n",
    "def merge_abs_ang(Sabs, Sang):\n",
    "    S = Sabs*np.exp(1j * Sang)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sabs, Sang = fft_transform_abs_angle(female_audio)\n",
    "\n",
    "line_plot_args([Sabs, Sang], labels=[\"Freq (Hz)\", \"Abs / Ang\"], x_range=[0,2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activity 02\n",
    "Extract the FFT module ($Sabs$) for `male_audio` signal and:\n",
    "- Plot both `male_audio` and `female_audio` $Sabs$ superposed\n",
    "- Compare the signals. What insights can we extract? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C. Pure Tone - Simple Speech Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURE TONES EXAMPLES - NOTE 'A'\n",
    "for freq in [110, 220, 440, 880, 1760, 3520]: \n",
    "    path_in = \"example_signals/pure_tones/\"+str(freq)+\"hz.wav\"\n",
    "    print(path_in)\n",
    "    display_audio(path_in)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCEMENT\n",
    "curr_path = \"example_signals/currupted_male.wav\"\n",
    "curr_audio, sr = read_wav(curr_path)\n",
    "\n",
    "line_plot_args([male_audio, curr_audio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_audio(MALE_AUDIOPATH)\n",
    "display_audio(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sabs, Sphs = fft_transform_abs_angle(male_audio)\n",
    "Sabs_curr, Sphs_curr = fft_transform_abs_angle(curr_audio)\n",
    "\n",
    "line_plot_args([Sabs, Sabs_curr], x_range=[0,8001], labels=[\"Frequency (Hz)\",\"Module\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scurr = merge_abs_ang(Sabs_curr, Sphs_curr)\n",
    "curr_audio_enh = ifft_transform(Scurr)\n",
    "\n",
    "path_enh = \"enhanced_file.wav\"\n",
    "write_wav(path_enh, curr_audio_enh, SR)\n",
    "\n",
    "display_audio(path_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,3)); plt.plot(Sabs_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activity 03\n",
    "Remove the pure tone noise in the `example_signals/currupted_female.wav`:\n",
    "- Identify where the pure tone is in $Sabs$.\n",
    "- Suppress it and restore the original audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA: PLAYFUL TONES   :)\n",
    "def gen_pure_tone(freq, SR=16000):\n",
    "    pure_tone = 0.05*np.sin( (2*np.pi * freq / SR) * np.arange(2*SR) )\n",
    "    return pure_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D. The Spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGNAL SAMPLES\n",
    "time_mark = 8000        # Center of Example Audios <=> 0.5 seconds \n",
    "\n",
    "window_ms = (20/1000)\n",
    "window_samples = int(window_ms*SR)\n",
    "\n",
    "print(\"Total window samples:\", window_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_samples = []\n",
    "\n",
    "for shift in [0, 320, 640]:\n",
    "    sample = female_audio[time_mark+shift : time_mark+shift+window_samples]\n",
    "    signal_samples.append(sample)\n",
    "    \n",
    "line_plot_args(signal_samples, x_norm=SR, labels=[\"Time (s)\", \"Amplitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECTRUM SAMPLES\n",
    "spec_samples = []\n",
    "\n",
    "for signal in signal_samples:\n",
    "    Sabs, Sphs = fft_transform_abs_angle(signal)\n",
    "    spec_samples.append(Sabs)\n",
    "\n",
    "line_plot_args(spec_samples)\n",
    "#line_plot_args(spec_samples, x_norm=window_samples/SR, x_range=[0, int(window_samples/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECTROGRAM FUNCTIONS \n",
    "def gen_spectrogram(audio, win_size=320, win_hop=160, dB=False, min_level=10 ** -8):\n",
    "    Spectrogram = []\n",
    "    \n",
    "    start = 0\n",
    "    end = win_size\n",
    "    shift = win_hop\n",
    "    \n",
    "    while end < len(audio):\n",
    "        frame = audio[start:end]\n",
    "        Sframe, _ = fft_transform_abs_angle(frame)\n",
    "        \n",
    "        Spectrogram.append(Sframe ** 2)\n",
    "        #Spectrogram.append(Sframe[:int(len(Sframe)/2 + 1)]**2)\n",
    "        \n",
    "        start+=shift\n",
    "        end+=shift\n",
    "    \n",
    "    Spectrogram = np.array(Spectrogram)\n",
    "    \n",
    "    if dB:\n",
    "        Spectrogram = 10*np.log10(Spectrogram + min_level)\n",
    "    \n",
    "    return Spectrogram\n",
    "\n",
    "\n",
    "def matrix_plot_args(args, y_norm=1, subplot=True, x_range=None, labels=[\"X\",\"Y\"], legend=None, transpose=True):\n",
    "    plt.figure(figsize=(12,3))\n",
    "    n_figs = len(args)\n",
    "    \n",
    "    for idx, arg in enumerate(args):\n",
    "        yy = np.arange(arg.shape[1]) / y_norm\n",
    "        \n",
    "        if x_range == None:\n",
    "            x_range = [0,len(arg)]\n",
    "\n",
    "        if subplot:\n",
    "            plt.subplot(1,n_figs,idx+1);\n",
    "        \n",
    "        if transpose:\n",
    "            plt.imshow(arg[x_range[0]:x_range[1]].T, aspect='auto', origin='lower')\n",
    "        else:\n",
    "            plt.imshow(arg[x_range[0]:x_range[1]], aspect='auto', origin='lower')\n",
    "            \n",
    "        plt.xlabel(labels[0]); plt.ylabel(labels[1]); plt.colorbar()\n",
    "        \n",
    "    if not subplot:\n",
    "        plt.legend(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_spec = gen_spectrogram(female_audio, win_size=320, win_hop=160, dB=True)\n",
    "male_spec = gen_spectrogram(male_audio, win_size=320, win_hop=160, dB=True)\n",
    "\n",
    "print(female_spec.shape)\n",
    "print(female_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_args(female_spec[49:52], x_norm=window_samples/SR, x_range=[0, int(window_samples/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.imshow(female_spec.T, aspect='auto', origin='lower')\n",
    "# plt.ylim([0, 100]); plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activity 04\n",
    "Compare the spectrogram of female and male audios (`female_spec` , `male_spec`):\n",
    "- Use `matrix_plot_args` to plot the spectrograms\n",
    "- What can be observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 04\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E. Padding a Signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_zeros(audio, total_size):\n",
    "    num_zeros = int(np.max([0, int(total_size - len(audio))]))\n",
    "    audio = np.concatenate([audio, np.zeros(num_zeros)])\n",
    "    return audio\n",
    "    \n",
    "    \n",
    "def gen_spectrogram_complete(audio, win_size=320, win_hop=160, n_fft=512, dB=False, min_level=10 ** -8):\n",
    "    Spectrogram = []\n",
    "    \n",
    "    start = 0\n",
    "    end = win_size\n",
    "    shift = win_hop\n",
    "    \n",
    "    while end < len(audio):\n",
    "        frame = padding_zeros(audio[start:end], n_fft)\n",
    "        Sframe, _ = fft_transform_abs_angle(frame)\n",
    "        \n",
    "        #Spectrogram.append(Sframe ** 2)\n",
    "        Spectrogram.append(Sframe[:int(len(Sframe)/2 + 1)]**2)\n",
    "        \n",
    "        start+=shift\n",
    "        end+=shift\n",
    "    \n",
    "    Spectrogram = np.array(Spectrogram)\n",
    "    \n",
    "    if dB:\n",
    "        Spectrogram = 10*np.log10(Spectrogram + min_level)\n",
    "    \n",
    "    return Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALC SPECTROGRAMS with PADDING\n",
    "female_spec = gen_spectrogram(female_audio, win_size=320, win_hop=160, dB=True)\n",
    "female_spec_complete = gen_spectrogram_complete(female_audio, win_size=320, win_hop=160, n_fft=512, dB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT SAMPLES\n",
    "line_plot_args(female_spec[49:52], x_norm=window_samples/SR, x_range=[0, int(window_samples/2)])\n",
    "line_plot_args(female_spec_complete[49:52], x_norm=window_samples/SR, x_range=[0, int(window_samples/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_plot_args([female_spec, female_spec_complete], labels=[\"Frames\", \"Energy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F. Mel-Spectrogram and MFCC \n",
    "<img src=\"images/mel_filterbank.png\" alt=\"Complex Numbers\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONAL FUNCTIONS\n",
    "def load_mel_filterbank(n_fft=512):\n",
    "    pkl_path = \"example_filters/mel_filter80_nfft\"+str(n_fft)+\"_sr16000.pkl\"\n",
    "    with open(pkl_path, \"rb\") as input_file:\n",
    "        mel_filter = pickle.load(input_file)\n",
    "    \n",
    "    return mel_filter\n",
    "\n",
    "def spec_2_melspec(S, n_fft):\n",
    "    mel_filter = load_mel_filterbank(n_fft)\n",
    "    mel_spec = mel_filter.dot(S.T)\n",
    "    \n",
    "    return mel_spec\n",
    "\n",
    "def melspec_2_mfcc(mel_spec, n_mfcc=13):\n",
    "    return scipy.fftpack.dct(mel_spec, axis=-2, type=2, norm=\"ortho\")[:13,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_mel_spec = spec_2_melspec(female_spec_complete, n_fft=512)\n",
    "female_mfcc = melspec_2_mfcc(female_mel_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_plot_args([female_mel_spec, female_mfcc], labels=[\"Frames\", \"Mel-Spec / MFCC\"], transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MALE VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activity 05\n",
    "Why (and when) do you think one should adopt the Mel-Spectrogram or the MFCC for a particurlar application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### G. Key-Word Detection (KWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwd_paths = [\"example_signals/librispeech_male251_i_am_going.wav\",\n",
    "             \"example_signals/kwd_class2.wav\",\n",
    "             \"example_signals/kwd_class3.wav\",\n",
    "             \"example_signals/kwd_class5.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwd_audios   = [read_wav(path) for path in kwd_paths]\n",
    "kwd_specs    = [gen_spectrogram_complete(audio, n_fft=512, dB=True) for audio,_ in kwd_audios]\n",
    "kwd_melspecs = [spec_2_melspec(specs, n_fft=512) for specs in kwd_specs]\n",
    "kwd_mfccs    = [melspec_2_mfcc(melspec) for melspec in kwd_melspecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_plot_args(kwd_melspecs, transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix_plot_args(kwd_mfccs, transpose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activity 06\n",
    "Two audios above correspond to the same spoken words. Could you identify which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### H. Music Recognition (Shazam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_paths = [\"example_signals/youtube_music01_ch01.wav\",\n",
    "              \"example_signals/youtube_music02_ch01.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_audios   = [read_wav(path) for path in music_paths]\n",
    "music_specs    = [gen_spectrogram_complete(audio, n_fft=512, dB=True) for audio,_ in music_audios]\n",
    "music_melspecs = [spec_2_melspec(specs, n_fft=512) for specs in music_specs]\n",
    "music_mfccs    = [melspec_2_mfcc(melspec) for melspec in music_melspecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_plot_args(music_melspecs, transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_plot_args(music_mfccs, transpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_audio(music_paths[0])\n",
    "display_audio(music_paths[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Activity 07\n",
    "What approach could be considered to perform music recognition using a TF Representation?\n",
    "\n",
    "(After thinking about it, you might want to look the Shazam paper: https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
